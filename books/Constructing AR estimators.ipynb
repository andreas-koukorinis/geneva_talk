{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n",
      "/opt/conda/lib/python3.5/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import talk.config as con\n",
    "\n",
    "con.config_configManager()\n",
    "con.config_matplotlib()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Constructing estimators \n",
    "------------------------\n",
    "https://en.wikipedia.org/wiki/Autoregressive_model\n",
    "\n",
    "#### Thomas Schmelzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A very common estimator is based on AR models (autoregressive)\n",
    "\n",
    "$$R_T = \\sum_{i=1}^n w_i r_{T-i}$$\n",
    "\n",
    "Predict the (unknown) return $R_T$ using the last $n$ previous returns. **Attention**: You may want to use volatility adjusted returns, apply filters etc.\n",
    " \n",
    "How to pick the $n$ free parameters in $\\mathbf{w}$? (Partial) autocorrelations? \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def convolution(ts, weights):\n",
    "    from statsmodels.tsa.filters.filtertools import convolution_filter\n",
    "    return convolution_filter(ts, weights, nsides=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     r  pred  before\n",
      "0  1.0   NaN     NaN\n",
      "1 -2.0  -3.0     NaN\n",
      "2  1.0   0.0    -3.0\n",
      "3  1.0   3.0     0.0\n",
      "4  1.5   4.0     3.0\n",
      "5  0.0   1.5     4.0\n",
      "6  2.0   4.0     1.5\n",
      "               r      pred    before\n",
      "r       1.000000  0.895788 -0.190159\n",
      "pred    0.895788  1.000000  0.538431\n",
      "before -0.190159  0.538431  1.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "r = pd.Series([1.0, -2.0, 1.0, 1.0, 1.5, 0.0, 2.0])\n",
    "weights = [2.0, 1.0]\n",
    "# trendfollowing == positive weights\n",
    "x=pd.DataFrame()\n",
    "x[\"r\"] = r\n",
    "x[\"pred\"] = convolution(r, weights)\n",
    "x[\"before\"] = x[\"pred\"].shift(1)\n",
    "print(x)\n",
    "print(x.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     r  pred  before\n",
      "0  1.0   NaN     NaN\n",
      "1 -2.0   3.0     NaN\n",
      "2  1.0   0.0     3.0\n",
      "3  1.0  -3.0     0.0\n",
      "4  1.5  -4.0    -3.0\n",
      "5  0.0  -1.5    -4.0\n",
      "6  2.0  -4.0    -1.5\n",
      "               r      pred    before\n",
      "r       1.000000 -0.895788  0.190159\n",
      "pred   -0.895788  1.000000  0.538431\n",
      "before  0.190159  0.538431  1.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# mean-reversion == negative weights\n",
    "r = pd.Series([1.0, -2.0, 1.0, 1.0, 1.5, 0.0, 2.0])\n",
    "weights = [-2.0, -1.0]\n",
    "x=pd.DataFrame()\n",
    "x[\"r\"] = r\n",
    "x[\"pred\"] = convolution(r, weights)\n",
    "x[\"before\"] = x[\"pred\"].shift(1)\n",
    "print(x)\n",
    "print(x.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Looking only at the last two returns might be a bit ...\n",
    "\n",
    "Is it a good idea to have $n=200$ free parameters?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "File b'SPX_Index.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-18279c3ba172>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# generate random returns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SPX_Index.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msqueeze\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpct_change\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# let's compute the optimal convolution!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpacf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnlags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    560\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    643\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    797\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    800\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1211\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas/parser.c:3427)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas/parser.c:6861)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: File b'SPX_Index.csv' does not exist"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.tsa.stattools as sts\n",
    "# generate random returns\n",
    "import pandas as pd\n",
    "r = pd.read_csv(\"SPX_Index.csv\", squeeze=True, index_col=0, parse_dates=True).pct_change().dropna()\n",
    "# let's compute the optimal convolution!\n",
    "weights = sts.pacf(r, nlags=200)\n",
    "pd.Series(data=weights[1:]).plot(kind=\"bar\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# The trading system! \n",
    "pos = convolution(r, weights[1:])\n",
    "pos = 1e6*(pos/pos.std())\n",
    "# profit = return[today] * position[yesterday]\n",
    "(r*pos.shift(1)).cumsum().plot()\n",
    "plt.xlabel('Time'), plt.ylabel('Profit')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Bias\n",
    "----\n",
    "\n",
    "We assume the weights are exponentially decaying, e.g.\n",
    "\n",
    "$$w_i = \\frac{1}{S}\\lambda^i$$\n",
    "\n",
    "where $S$ is a suitable scaling constant and $\\lambda = 1-1/N$. Note that $N \\neq n$.\n",
    "\n",
    "**Everything** that is **not** an exponentially weighted moving average is **wrong**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def exp_weights(m, n=100):\n",
    "    x = np.power(1.0 - 1.0/m, range(1,n+1))\n",
    "    S = np.linalg.norm(x)\n",
    "    return x/S\n",
    "\n",
    "pd.Series(exp_weights(m=16,n=40)).plot(kind=\"bar\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "periods = [2,4,6,8,12,16,24,32,48,64,96,192]\n",
    "# matrix of weights\n",
    "W = pd.DataFrame({period : exp_weights(m=period, n=200) for period in periods}) \n",
    "W.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# each column of A is a convoluted return time series\n",
    "A = pd.DataFrame({period : convolution(r, W[period]).shift(1) for period in periods})  \n",
    "\n",
    "A = A.dropna(axis=0)\n",
    "r = r[A.index].dropna()\n",
    "\n",
    "A.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "(Naive) regression\n",
    "-------------------\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf{w}^{*}=\\arg\\min_{\\mathbf{w} \\in \\mathbb{R}^m}& \\rVert{\\mathbf{A}\\mathbf{w} - \\mathbf{r}}\\lVert_2 \n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from numpy.linalg import lstsq\n",
    "# sometimes you don't need to use MOSEK :-)\n",
    "weights = pd.Series(index=periods, data=lstsq(A.values, r.values)[0])\n",
    "print(weights)\n",
    "(W*weights).sum(axis=1).plot(kind=\"bar\")\n",
    "(W*weights).sum(axis=1).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Mean variation\n",
    "\n",
    "We provide a few indicators. Avoid fast indicators. Prefer slower indicators as they induce less trading costs.\n",
    "Use the mean variation of the signal (convoluted returns here)\n",
    "\n",
    "$$f(\\mathbf{x}) = \\frac{1}{n}\\sum{\\lvert x_i - x_{i-1}\\rvert}=\\frac{1}{n}\\rVert{\\Delta \\mathbf{x}}\\lVert_1$$\n",
    "\n",
    "The $i$th column of $\\mathbf{A}$ has a mean variation $d_i$. We introduce the diagonal penalty matrix $\\mathbf{D}$ with $D_{i,i}=d_i$.\n",
    "\n",
    "$$\\mathbf{w}^{*}=\\arg\\min_{\\mathbf{w} \\in \\mathbb{R}^m} \\lVert{\\mathbf{Aw}-\\mathbf{r}}\\rVert_2 + \\lambda \\rVert{\\mathbf{Dw}}\\lVert_1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def mean_variation(ts):\n",
    "    return ts.diff().abs().mean()\n",
    "\n",
    "d = A.apply(mean_variation)\n",
    "D = np.diag(d)\n",
    "    \n",
    "from mosek.fusion import *\n",
    "# but you could use Mosek: \n",
    "def __two_norm(model, v):\n",
    "    # add variable to model for the 2-norm of the residual\n",
    "    x = model.variable(1, Domain.greaterThan(0.0))\n",
    "    # add the quadratic cone\n",
    "    model.constraint(Expr.vstack(x,v), Domain.inQCone())\n",
    "    return x\n",
    "\n",
    "\n",
    "def __one_norm(model, v):\n",
    "    t = model.variable(int(v.size()), Domain.greaterThan(0.0))\n",
    "    model.constraint(Expr.hstack(t, v), Domain.inQCone(int(v.size()), 2))\n",
    "    return Expr.sum(t)\n",
    "\n",
    "\n",
    "def ar(A, D, r, lamb=0.0):\n",
    "\n",
    "    with Model('lasso') as model:\n",
    "        n = int(A.shape[1])\n",
    "        # introduce the variable for the var\n",
    "        x = model.variable(\"x\", n, Domain.unbounded())\n",
    "        # minimization of the conditional value at risk\n",
    "        a1 = __two_norm(model, Expr.sub(Expr.mul(DenseMatrix(A),x), Expr.constTerm(r)))\n",
    "        a2 = __one_norm(model, Expr.mul(DenseMatrix(D),x))\n",
    "        \n",
    "        model.objective(ObjectiveSense.Minimize, Expr.add(a1, Expr.mul(a2, float(lamb))))\n",
    "        model.solve()\n",
    "\n",
    "        return x.level()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "t_weight = dict()\n",
    "for lamb in [0.0, 1.0, 2.0, 3.0, 5.0, 7.0, 9.0, 12.0, 15.0]:\n",
    "    weights = pd.Series(index=periods, data=ar(A.values, D, r.values, lamb=lamb))\n",
    "    print(weights.transpose())\n",
    "    t_weight[lamb] = (W*weights).sum(axis=1)\n",
    "    t_weight[lamb].plot(kind=\"bar\")\n",
    "    t_weight[lamb].plot()\n",
    "    plt.title(lamb)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "for lamb in sorted(t_weight.keys()):\n",
    "    pos = convolution(r, t_weight[lamb])\n",
    "    pos = 1e6*(pos/pos.std())\n",
    "    (r*pos.shift(1)).cumsum().plot()\n",
    "    plt.title(lamb)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "d = A.apply(mean_variation)\n",
    "D = np.diag(d)\n",
    "weights = pd.Series(index=periods, data=ar(A.values, D, r.values, lamb=3.0))\n",
    "print(weights)\n",
    "# let's make the first two moving averages really expensive!\n",
    "\n",
    "d = A.apply(mean_variation)\n",
    "D = np.diag(d)\n",
    "D[0,0] = 100*D[0,0]\n",
    "D[1,1] = 100*D[1,1]\n",
    "a = pd.Series(index=periods, data=ar(A.values, D, r.values, lamb=3.0))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary\n",
    "\n",
    "- The problem of constructing an estimator is corresponds to tracking an index. The index is here a historic return time series. The **assets** are standard estimators. \n",
    "\n",
    "\n",
    "- Using the (mean) total variation of the signals can help to prefer slower signals rather than expensive fast signals.\n",
    "\n",
    "\n",
    "- Using a penalty induced by the $1$-norm (see LARS, LASSO) it is possible to establish a ranking amongst the indicators and construct them robustly. \n",
    "\n",
    "\n",
    "- It is possible to (vertical) stack the resulting systems to find optimal weights across a group of assets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a href=http://localhost:8888>Back to Overview</a>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
